{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSDS631 - Deep Learning Final Project 2019 \n",
    "## Quora Insincere Questions Classification\n",
    "Detect toxic content to improve online conversations\n",
    "\n",
    "----\n",
    "### _Team: Jenny Kong & Joy Qi_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:44:28.601363Z",
     "start_time": "2019-06-14T22:44:26.043604Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from spacy.symbols import ORTH\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:44:29.315522Z",
     "start_time": "2019-06-14T22:44:29.300393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../input/.DS_Store'),\n",
       " PosixPath('../input/test.csv'),\n",
       " PosixPath('../input/train.csv'),\n",
       " PosixPath('../input/glove.6B'),\n",
       " PosixPath('../input/sample_submission.csv')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = Path(\"../input/\")\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:44:33.524936Z",
     "start_time": "2019-06-14T22:44:30.184893Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(PATH/\"train.csv\")\n",
    "df_test = pd.read_csv(PATH/\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:44:33.531307Z",
     "start_time": "2019-06-14T22:44:33.527344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (1306122, 3)\n",
      "Test shape:  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape: \", df_train.shape)\n",
    "print(\"Test shape: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:44:33.545569Z",
     "start_time": "2019-06-14T22:44:33.533636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:44:35.518929Z",
     "start_time": "2019-06-14T22:44:35.511282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
       "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
       "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n",
       "3  000086e4b7e1c7146103                             Who are entrepreneurs?\n",
       "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:44:37.126492Z",
     "start_time": "2019-06-14T22:44:37.103803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1225312\n",
       "1      80810\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:44:37.788577Z",
     "start_time": "2019-06-14T22:44:37.783271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              object\n",
       "question_text    object\n",
       "target            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:44:39.664288Z",
     "start_time": "2019-06-14T22:44:39.428394Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['question_text'] = df_train['question_text'].astype(str)\n",
    "df_train['qid'] = df_train['qid'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:44:41.992601Z",
     "start_time": "2019-06-14T22:44:41.243899Z"
    }
   },
   "outputs": [],
   "source": [
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
    "\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:44:42.945811Z",
     "start_time": "2019-06-14T22:44:42.935353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How',\n",
       " 'did',\n",
       " 'Quebec',\n",
       " 'nationalists',\n",
       " 'see',\n",
       " 'their',\n",
       " 'province',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nation',\n",
       " 'in',\n",
       " 'the',\n",
       " '1960s',\n",
       " '?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df_train['question_text'][0]\n",
    "spacy_tok(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:51:40.457530Z",
     "start_time": "2019-06-14T22:44:44.693693Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "for q in df_train['question_text']:\n",
    "    counts.update(spacy_tok(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:51:44.474252Z",
     "start_time": "2019-06-14T22:51:44.470044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262118"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:51:45.282952Z",
     "start_time": "2019-06-14T22:51:45.107578Z"
    }
   },
   "outputs": [],
   "source": [
    "for word in list(counts):\n",
    "    if counts[word] < 5:\n",
    "        del counts[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:51:45.830060Z",
     "start_time": "2019-06-14T22:51:45.825588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57655"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:51:46.687174Z",
     "start_time": "2019-06-14T22:51:46.658369Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:51:48.572623Z",
     "start_time": "2019-06-14T22:51:48.563087Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_sentence(row, vocab2index, N=100, padding_start=True):\n",
    "    words = spacy_tok(row)\n",
    "    enc = np.zeros(N, dtype=np.int32)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in words])\n",
    "    l = min(N, len(enc1))\n",
    "    if padding_start:\n",
    "        enc[:l] = enc1[:l]\n",
    "    else:\n",
    "        enc[N-l:] = enc1[:l]\n",
    "    return enc, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:51:49.053871Z",
     "start_time": "2019-06-14T22:51:49.047410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
       "       dtype=int32), 14)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_sentence(df_train['question_text'][0], vocab2index, N=100, padding_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select max sequece length N according to the 98th percentile length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:51:52.221403Z",
     "start_time": "2019-06-14T22:51:50.642003Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_len = np.array([len(q.split()) for q in df_train['question_text']])\n",
    "x_test_len = np.array([len(q.split()) for q in df_test['question_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:51:52.729196Z",
     "start_time": "2019-06-14T22:51:52.723214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 87)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_len.max(), x_test_len.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:51:53.576228Z",
     "start_time": "2019-06-14T22:51:53.546670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39.0, 39.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 99 percentile\n",
    "N_train = np.percentile(x_train_len, 99)\n",
    "N_test = np.percentile(x_test_len, 99)\n",
    "\n",
    "N_train, N_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hence we chose 50 to be the N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:51:55.143055Z",
     "start_time": "2019-06-14T22:51:55.140293Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:51:57.049145Z",
     "start_time": "2019-06-14T22:51:56.279347Z"
    }
   },
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:51:57.539278Z",
     "start_time": "2019-06-14T22:51:57.534734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1044897, 3), (261225, 3))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:52:10.996769Z",
     "start_time": "2019-06-14T22:52:10.990424Z"
    }
   },
   "outputs": [],
   "source": [
    "# class QuoraDataset(Dataset):\n",
    "#     def __init__(self, df, vocab2index, is_test=False, N=40, padding_start=True):\n",
    "#         self.question = [encode_sentence(q, vocab2index, N, padding_start) for q in df['question_text']]\n",
    "#         self.is_test = is_test\n",
    "#         if self.is_test:\n",
    "#             self.y = None\n",
    "#         else:\n",
    "#             self.y = list(df[\"target\"])\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.question)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         x = self.question[idx]\n",
    "#         if self.is_test:\n",
    "#             return x\n",
    "#         else:\n",
    "#             y = self.y[idx]\n",
    "#             return x, y\n",
    "\n",
    "class QuoraDataset(Dataset):\n",
    "    def __init__(self, df, vocab2index, is_test=False, N=40, padding_start=True):\n",
    "        self.question = [encode_sentence(q, vocab2index, N, padding_start) for q in df['question_text']]\n",
    "        self.is_test = is_test\n",
    "        if self.is_test:\n",
    "            self.y = None\n",
    "        else:\n",
    "            self.y = list(df[\"target\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, s = self.question[idx]\n",
    "        \n",
    "        if self.is_test:\n",
    "            return x\n",
    "        else:\n",
    "            y = self.y[idx]\n",
    "            return x, s, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:59:57.511320Z",
     "start_time": "2019-06-14T22:52:11.955539Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = QuoraDataset(train, vocab2index, N=40, padding_start=False)\n",
    "valid_ds = QuoraDataset(valid, vocab2index, N=40, padding_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T23:02:05.847157Z",
     "start_time": "2019-06-14T23:02:05.843169Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T22:44:00.399268Z",
     "start_time": "2019-06-14T22:44:00.299964Z"
    }
   },
   "outputs": [],
   "source": [
    "# x, y = next(iter(train_dl))\n",
    "x,s,y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T23:02:29.214415Z",
     "start_time": "2019-06-14T23:02:29.073417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x, y = next(iter(train_dl))\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T23:11:28.962933Z",
     "start_time": "2019-06-14T23:11:28.959031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 40])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T23:02:35.378089Z",
     "start_time": "2019-06-14T23:02:35.373644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "          123,    92,    13,   927,    29,  1763,   175, 24124,  5966,\n",
       "        35388,     1,     1,    15], dtype=int32), 13, 0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile=\"../input/glove.6B/glove.6B.300d.txt\"):\n",
    "    \"\"\" Loads word vectors into a dictionary.\"\"\"\n",
    "    f = open(gloveFile,'r')\n",
    "    word_vecs = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        word_vecs[word] = np.array([float(val) for val in splitLine[1:]])\n",
    "    return word_vecs\n",
    "word_vecs = loadGloveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_word_vector(D=300):\n",
    "    \"\"\"Create arandom word vector\n",
    "    \n",
    "    0.25 is chosen so the unknown vectors have (approximately) same variance \n",
    "    as pre-trained ones\n",
    "    \"\"\"\n",
    "    return np.random.uniform(-0.25,0.25,D)\n",
    "\n",
    "def create_embedding_matrix(word_vecs, vocab2index, words, D=300):\n",
    "    \"\"\"Creates embedding matrix from word vectors. \"\"\"\n",
    "    V = len(words)\n",
    "    W = np.zeros((V, D), dtype=\"float32\")\n",
    "    W[0] = np.zeros(D, dtype='float32')\n",
    "    i = 1\n",
    "    for i in range(1, V):\n",
    "        if words[i] in word_vecs:\n",
    "            W[i] = word_vecs[words[i]]\n",
    "        else:\n",
    "            W[i] = random_word_vector()\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57657, 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = create_embedding_matrix(word_vecs, vocab2index, words)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T23:12:21.807689Z",
     "start_time": "2019-06-14T23:12:21.800734Z"
    }
   },
   "outputs": [],
   "source": [
    "# class LSTMModel(torch.nn.Module) :\n",
    "#     def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "#         super(LSTMModel,self).__init__()\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "#         self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)  # (batch, seq, feature)\n",
    "#         self.linear = nn.Linear(hidden_dim, 1)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x_emb = self.embeddings(x)\n",
    "#         x_drop = self.dropout(x_emb)\n",
    "#         out_pack, (ht, ct) = self.lstm(x_drop)\n",
    "#         return self.linear(ht[-1])\n",
    "class GRUModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, embedding_matrix):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "        self.embedding.weight.requires_grad = False ## freeze embeddings\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        s, sort_index = torch.sort(s, 0,descending=True)\n",
    "        s = s.numpy().tolist()\n",
    "        x = x[sort_index]\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        x_pack = pack_padded_sequence(x, list(s), batch_first=True)\n",
    "        out_pack, ht= self.gru(x_pack)\n",
    "        out = self.linear(ht[-1])\n",
    "        return torch.zeros_like(out).scatter_(0, sort_index.unsqueeze(1), out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_epocs(model, epochs=10, lr=0.001):\n",
    "#     parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "#     optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "#     for i in range(epochs):\n",
    "#         model.train()\n",
    "#         sum_loss = 0.0\n",
    "#         total = 0\n",
    "#         for x, s, y in train_dl:\n",
    "#             x = x.long()\n",
    "#             y = y.float()\n",
    "#             y_pred = model(x, s)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             sum_loss += loss.item()*y.shape[0]\n",
    "#             total += y.shape[0]\n",
    "#         val_loss, val_acc = val_metrics(model, val_dl)\n",
    "#         if i % 5 == 1:\n",
    "#             print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def val_metrics(model, valid_dl):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     sum_loss = 0.0\n",
    "#     for x, s, y in valid_dl:\n",
    "#         x = x.long().cuda()\n",
    "#         y = y.float().cuda().unsqueeze(1)\n",
    "#         y_hat = model(x, s)\n",
    "#         loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "#         y_pred = y_hat > 0\n",
    "#         correct += (y_pred.float() == y).float().sum()\n",
    "#         total += y.shape[0]\n",
    "#         sum_loss += loss.item()*y.shape[0]\n",
    "#     return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T23:21:04.041459Z",
     "start_time": "2019-06-14T23:21:04.034955Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epocs(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, s, y in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.float()\n",
    "            y_pred = model(x, s)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))\n",
    "\n",
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, s, y in valid_dl:\n",
    "        x = x.long()\n",
    "        y = y.float().unsqueeze(1)\n",
    "        y_hat = model(x, s)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        y_pred = y_hat > 0\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total\n",
    "\n",
    "# def train_epocs(model, epochs=10, lr=0.001):\n",
    "#     parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "#     optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "#     for i in range(epochs):\n",
    "#         model.train()\n",
    "#         sum_loss = 0.0\n",
    "#         total = 0\n",
    "#         for x, y in train_dl:\n",
    "#             x = torch.tensor(x[0], dtype=torch.long)\n",
    "#             y = y.float()\n",
    "#             y_pred = model(x)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             sum_loss += loss.item()*y.shape[0]\n",
    "#             total += y.shape[0]\n",
    "#         val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "#         if i % 5 == 1:\n",
    "#             print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T23:21:04.391796Z",
     "start_time": "2019-06-14T23:21:04.386401Z"
    }
   },
   "outputs": [],
   "source": [
    "# def val_metrics(model, valid_dl):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     sum_loss = 0.0\n",
    "#     for x, y in valid_dl:\n",
    "#         x = torch.tensor(x[0], dtype=torch.long)\n",
    "#         y = y.float().unsqueeze(1)\n",
    "#         y_hat = model(x)\n",
    "#         loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "#         y_pred = y_hat > 0\n",
    "#         correct += (y_pred.float() == y).float().sum()\n",
    "#         total += y.shape[0]\n",
    "#         sum_loss += loss.item()*y.shape[0]\n",
    "#     return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T23:21:05.247265Z",
     "start_time": "2019-06-14T23:21:05.243987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57657\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T23:21:05.729787Z",
     "start_time": "2019-06-14T23:21:05.704627Z"
    }
   },
   "outputs": [],
   "source": [
    "model = GRUModel(vocab_size, 300, 50, embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T09:55:38.134193Z",
     "start_time": "2019-06-16T03:34:40.451520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.199 val loss 0.196 and val accuracy 0.944\n",
      "train loss 0.198 val loss 0.196 and val accuracy 0.944\n",
      "train loss 0.198 val loss 0.197 and val accuracy 0.944\n",
      "CPU times: user 2h 52min 52s, sys: 23min 29s, total: 3h 16min 21s\n",
      "Wall time: 1h 8min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_epocs(model, epochs=15, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T19:03:58.597719Z",
     "start_time": "2019-06-16T19:03:58.586785Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(m, p): \n",
    "    torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): \n",
    "    m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T19:04:31.808759Z",
     "start_time": "2019-06-16T19:04:31.785683Z"
    }
   },
   "outputs": [],
   "source": [
    "p1 = \"./models/model-96.pth\"\n",
    "save_model(model, p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T19:05:54.324473Z",
     "start_time": "2019-06-16T19:05:54.272314Z"
    }
   },
   "outputs": [],
   "source": [
    "model1 = LSTMModel(vocab_size, 50, 50)\n",
    "model_path = \"./models/model-96.pth\"\n",
    "load_model(model1, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T19:08:45.785807Z",
     "start_time": "2019-06-16T19:06:44.306314Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ds = QuoraDataset(df_test, vocab2index, is_test=True, N=40, padding_start=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T19:42:14.156932Z",
     "start_time": "2019-06-16T19:42:14.154562Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv(PATH/\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T20:18:21.364898Z",
     "start_time": "2019-06-16T20:16:49.979258Z"
    }
   },
   "outputs": [],
   "source": [
    "preds=[]\n",
    "for x in test_dl:\n",
    "    x = x[0].long()\n",
    "    out = model(x)\n",
    "    pred = (out > 0.0).long()\n",
    "    preds.append(pred.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T20:18:41.511857Z",
     "start_time": "2019-06-16T20:18:41.503740Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submission['prediction'] = np.vstack(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T20:18:46.437999Z",
     "start_time": "2019-06-16T20:18:46.428905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  prediction\n",
       "0  0000163e3ea7c7a74cd7           1\n",
       "1  00002bd4fb5d505b9161           0\n",
       "2  00007756b4a147d2b0b3           0\n",
       "3  000086e4b7e1c7146103           0\n",
       "4  0000c4c3fbe8785a3090           0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T20:19:42.294310Z",
     "start_time": "2019-06-16T20:19:41.361467Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
